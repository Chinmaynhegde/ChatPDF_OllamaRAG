{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ingesting PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --q unstructured langchain  --quiet\n",
    "!pip install --q \"unstructured[all-docs]\" --quiet   #for loading all pdf ,text etc files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-community in c:\\users\\chinmay hegde\\documents\\chatpdf_ollama\\myenv\\lib\\site-packages (0.2.1)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\chinmay hegde\\documents\\chatpdf_ollama\\myenv\\lib\\site-packages (from langchain-community) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\chinmay hegde\\documents\\chatpdf_ollama\\myenv\\lib\\site-packages (from langchain-community) (2.0.30)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\chinmay hegde\\documents\\chatpdf_ollama\\myenv\\lib\\site-packages (from langchain-community) (3.9.5)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\chinmay hegde\\documents\\chatpdf_ollama\\myenv\\lib\\site-packages (from langchain-community) (0.6.6)\n",
      "Requirement already satisfied: langchain<0.3.0,>=0.2.0 in c:\\users\\chinmay hegde\\documents\\chatpdf_ollama\\myenv\\lib\\site-packages (from langchain-community) (0.2.1)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.0 in c:\\users\\chinmay hegde\\documents\\chatpdf_ollama\\myenv\\lib\\site-packages (from langchain-community) (0.2.3)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in c:\\users\\chinmay hegde\\documents\\chatpdf_ollama\\myenv\\lib\\site-packages (from langchain-community) (0.1.67)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\chinmay hegde\\documents\\chatpdf_ollama\\myenv\\lib\\site-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\chinmay hegde\\documents\\chatpdf_ollama\\myenv\\lib\\site-packages (from langchain-community) (2.32.3)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\chinmay hegde\\documents\\chatpdf_ollama\\myenv\\lib\\site-packages (from langchain-community) (8.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\chinmay hegde\\documents\\chatpdf_ollama\\myenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\chinmay hegde\\documents\\chatpdf_ollama\\myenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\chinmay hegde\\documents\\chatpdf_ollama\\myenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\chinmay hegde\\documents\\chatpdf_ollama\\myenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\chinmay hegde\\documents\\chatpdf_ollama\\myenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\chinmay hegde\\documents\\chatpdf_ollama\\myenv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.21.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\chinmay hegde\\documents\\chatpdf_ollama\\myenv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in c:\\users\\chinmay hegde\\documents\\chatpdf_ollama\\myenv\\lib\\site-packages (from langchain<0.3.0,>=0.2.0->langchain-community) (0.2.0)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\chinmay hegde\\documents\\chatpdf_ollama\\myenv\\lib\\site-packages (from langchain<0.3.0,>=0.2.0->langchain-community) (2.7.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\chinmay hegde\\documents\\chatpdf_ollama\\myenv\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.0->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\chinmay hegde\\documents\\chatpdf_ollama\\myenv\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.0->langchain-community) (23.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\chinmay hegde\\documents\\chatpdf_ollama\\myenv\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (3.10.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\chinmay hegde\\documents\\chatpdf_ollama\\myenv\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\chinmay hegde\\documents\\chatpdf_ollama\\myenv\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\chinmay hegde\\documents\\chatpdf_ollama\\myenv\\lib\\site-packages (from requests<3,>=2->langchain-community) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\chinmay hegde\\documents\\chatpdf_ollama\\myenv\\lib\\site-packages (from requests<3,>=2->langchain-community) (2024.2.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\chinmay hegde\\documents\\chatpdf_ollama\\myenv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (4.12.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\chinmay hegde\\documents\\chatpdf_ollama\\myenv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\chinmay hegde\\documents\\chatpdf_ollama\\myenv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain-community) (2.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\chinmay hegde\\documents\\chatpdf_ollama\\myenv\\lib\\site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.0->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.3 in c:\\users\\chinmay hegde\\documents\\chatpdf_ollama\\myenv\\lib\\site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.0->langchain-community) (2.18.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\chinmay hegde\\documents\\chatpdf_ollama\\myenv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -U langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredPDFLoader\n",
    "from langchain.document_loaders import OnlinePDFLoader      #use to load online files\n",
    "\n",
    "local_path = \"ML_unit4_ensemble learning (1).pdf\"\n",
    "\n",
    "# Local PDF file uploads\n",
    "if local_path:\n",
    "    loader = UnstructuredPDFLoader(file_path=local_path)\n",
    "    data = loader.load()\n",
    "    \n",
    "else:\n",
    "    print(\"Upload a PDF file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vector Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!ollama pull nomic-embed-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                   \tID          \tSIZE  \tMODIFIED               \n",
      "nomic-embed-text:latest\t0a109f422b47\t274 MB\tLess than a second ago\t\n"
     ]
    }
   ],
   "source": [
    "!ollama list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip available: 22.3 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install --q chromadb\n",
    "!pip install --q langchain-text-splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split and chunk \n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=7500, chunk_overlap=100)\n",
    "chunks = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 2/2 [00:09<00:00,  4.69s/it]\n"
     ]
    }
   ],
   "source": [
    "# Add to vector database\n",
    "vector_db = Chroma.from_documents(\n",
    "    documents=chunks, \n",
    "    embedding=OllamaEmbeddings(model=\"nomic-embed-text\",show_progress=True),\n",
    "    collection_name=\"local-rag\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ollama pull mistral\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                   \tID          \tSIZE  \tMODIFIED       \n",
      "mistral:latest         \t2ae6f6dd7a3d\t4.1 GB\t2 minutes ago \t\n",
      "nomic-embed-text:latest\t0a109f422b47\t274 MB\t58 minutes ago\t\n"
     ]
    }
   ],
   "source": [
    "!ollama list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM from Ollama\n",
    "local_model = \"mistral\"\n",
    "llm = ChatOllama(model=local_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"\"\"You are an AI language model assistant. Your task is to generate five\n",
    "    different versions of the given user question to retrieve relevant documents from\n",
    "    a vector database. By generating multiple perspectives on the user question, your\n",
    "    goal is to help the user overcome some of the limitations of the distance-based\n",
    "    similarity search. Provide these alternative questions separated by newlines.\n",
    "    Original question: {question}\"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = MultiQueryRetriever.from_llm(\n",
    "    vector_db.as_retriever(), \n",
    "    llm,\n",
    "    prompt=QUERY_PROMPT\n",
    ")\n",
    "\n",
    "# RAG prompt\n",
    "template = \"\"\"Answer the question based ONLY on the following context:\n",
    "{context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:04<00:00,  4.26s/it]\n",
      "Number of requested results 4 is greater than number of elements in index 2, updating n_results = 2\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.07s/it]\n",
      "Number of requested results 4 is greater than number of elements in index 2, updating n_results = 2\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.07s/it]\n",
      "Number of requested results 4 is greater than number of elements in index 2, updating n_results = 2\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.17s/it]\n",
      "Number of requested results 4 is greater than number of elements in index 2, updating n_results = 2\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.28s/it]\n",
      "Number of requested results 4 is greater than number of elements in index 2, updating n_results = 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' The steps for AdaBoosting, or Adaptive Boosting, can be summarized as follows:\\n\\n1. Initialize the weak learners: Start with a collection of weak learners (usually decision trees or simple classifiers). Each weak learner produces a classification function that maps input features to outputs.\\n\\n2. Assign weights: Initially, all the data points are assigned equal weights. However, AdaBoosting dynamically adjusts these weights during training based on the errors made by the previous weak learners. After each round of training, the misclassified examples get more weight.\\n\\n3. Train each weak learner: For each weak learner, train it using the data points with their updated weights from step 2. The goal is to minimize the weighted error rate on the given dataset.\\n\\n4. Combine weak learners: Combine the outputs of all the weak learners into a single ensemble by taking weighted sums or averages (depending on whether the weak learners are linear or non-linear).\\n\\n5. Normalize weights: After combining all the weak learners, normalize the resulting weight function so that it sums up to 1 and each output value lies between -1 and 1. The normalization factor is usually the exponential of the negative sum of the logarithms of the individual outputs.\\n\\n6. Check for stopping condition: If a stopping condition (e.g., maximum number of rounds or small enough weighted error rate) is not met, go back to step 2 and repeat the process with updated weights for the next weak learner.\\n\\n7. Final prediction: Make the final prediction by applying the normalized combined function on the new data point. The output will be a real value between -1 and +1, with larger values indicating higher confidence in the predicted class.'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"What are the steps for Adaboosting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:04<00:00,  4.28s/it]\n",
      "Number of requested results 4 is greater than number of elements in index 2, updating n_results = 2\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.10s/it]\n",
      "Number of requested results 4 is greater than number of elements in index 2, updating n_results = 2\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.10s/it]\n",
      "Number of requested results 4 is greater than number of elements in index 2, updating n_results = 2\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.18s/it]\n",
      "Number of requested results 4 is greater than number of elements in index 2, updating n_results = 2\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:02<00:00,  2.25s/it]\n",
      "Number of requested results 4 is greater than number of elements in index 2, updating n_results = 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" Boosting and Bagging are two popular ensemble learning techniques used to improve the performance of machine learning models. Here are the main differences between them:\\n\\n1. Aim: The goal of Boosting is to correct the weaknesses of a base learner by giving it more weight on instances that it has misclassified, while Bagging aims to reduce variance and overfitting by combining multiple models trained on different subsets of the data.\\n\\n2. Training process: In Boosting, each new model (called a weak learner) is trained to correct the mistakes made by its predecessor. This results in stronger models being produced sequentially. Bagging, on the other hand, trains all the models simultaneously and combines their predictions.\\n\\n3. Voting scheme: When it comes to making predictions, Boosting uses a weighted majority vote where more weight is given to the stronger models, while Bagging uses a simple averaging or voting (majority) of the outputs from individual models.\\n\\n4. Example: A popular example of Boosting is AdaBoost, and an example of Bagging is Random Forest.\\n\\n5. Handling missing values and outliers: Boosting algorithms can handle missing values and outliers more effectively as they are less susceptible to overfitting due to their adaptive nature. Bagging, however, requires imputation or removal of instances with missing data before training the models.\\n\\n6. Computational complexity: Bagging has lower computational complexity since it trains all models at once and parallelization is easier to achieve compared to Boosting, which sequentially trains each model one by one.\\n\\n7. Final classifier: In Boosting, the final classifier tends to be more interpretable since it's built upon simple weak learners that can be easily understood. The final classifier in Bagging, on the other hand, may not be as interpretable due to its complex structure of multiple models.\\n\\nBoth Boosting and Bagging have their strengths and weaknesses, and choosing between them depends on the specific requirements of your machine learning problem such as the nature of the data, computational resources available, and desired level of interpretability in the final model.\""
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"What are the differences between boosting and bagging\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete all collections in the db\n",
    "vector_db.delete_collection()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
